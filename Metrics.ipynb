{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAl8zFzYBG+pMlguuXcnUe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewPelter/BCS109/blob/master/Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJt9u0NRL1pg"
      },
      "source": [
        "1. **Explain in words what accuracy, precision, and recall are.  Describe a situation when you would prefer one to another and where the shortcomings to each lays.** \n",
        "\n",
        "Accuracy is the most simple way to measure performance. It is a ratio of correctly predicted observations to the total observations. Or, the true positives plus the true negatives over all observations.\n",
        "\n",
        "Precision attempts to answer how many of the positive identifications were actually correct. You take the true positives and divide them by all of the positives (true positives and false positives).\n",
        "\n",
        "Lastly, recall determines what proportion of actual positives were actually identified correctly. This is accomplished by taking the true positives and dividing by the true postives plus the false negatives.\n",
        "\n",
        "Accuracy is very simple and could really be used for anything. Precision is used to determine how many times you were accurate. Recall is then used to see how accurate were the positives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRFI_ZIxNtC8"
      },
      "source": [
        "2. **What is a confusion matrix?**\n",
        "\n",
        "A confusion matrix is a summary of the number of correct and incorrect predictions made. It is used to measure the performance of a classification model and to confirm the accuracy and precision of the classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRQ5DblOOirg"
      },
      "source": [
        "3. **Write the python code for accuracy, precision, recall, and F1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEruDHeHPOud",
        "outputId": "48446339-3470-4e76-a93c-22e59998457f"
      },
      "source": [
        "# Accuracy\n",
        "\n",
        "#True positives\n",
        "TP = 42\n",
        "#True negatives\n",
        "TN = 32\n",
        "#False positives\n",
        "FP = 8\n",
        "#False negatives\n",
        "FN = 18\n",
        "\n",
        "Accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
        "print(f\"accuracy: {Accuracy}\")\n",
        "\n",
        "# Precision\n",
        "precision = TP / (TP + FP)\n",
        "print(f\"precision: {precision:4.2f}\")\n",
        "\n",
        "# Recall\n",
        "recall = TP / (TP + FN)\n",
        "print(f\"recall: {recall:4.2f}\")\n",
        "\n",
        "# F1\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "print(f\"f1: {f1_score:4.2f}\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.74\n",
            "precision: 0.84\n",
            "recall: 0.70\n",
            "f1: 0.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSMNdB3_YqLn"
      },
      "source": [
        "4. **Give your own example of a type 1 and type 2 error**\n",
        "\n",
        "Type 1 Error (False Positive Error):\n",
        "\n",
        "It was tested that the lady was not pregnant. Although she was not pregnant, she was still sent to the hospital and was prepared to give birth.\n",
        "\n",
        "Type 2 Error (False Negative):\n",
        "It was tested that the lady WAS pregnant. It is assumed that it is incorrect and she was not sent to the hospital even though she acutally is pregnant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTrZZD2gda8w"
      },
      "source": [
        "5. Why do we use train.test,split() function from Python when analyzing data?  What is the point of splitting data?\n",
        "\n",
        "You split data in order to form training data and testing data. You set apart of the array to be training data which will train the model. The other part of the array is set as the testing data which will confirm the accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPckH4Hzd0Mj"
      },
      "source": [
        "6. **What is the bias vs. variance tradeoff?**\n",
        "\n",
        "Bias is the difference between the average prediction of the model and the correct value which is trying to be predicted. High bias models pay little attention to the training data and oversimplifies the data.\n",
        "\n",
        "Variance is the variability of model prediction for a given data point. High variance pays a lot of attention to training data and does not generalize on the data it hasnt seen before.\n",
        "\n",
        "Generally, you want something in the middle. You do not want a high bias model because it could lead to many error rates on training and test data but you also do not want a model with high variance because it could lead to high error rates on test data."
      ]
    }
  ]
}